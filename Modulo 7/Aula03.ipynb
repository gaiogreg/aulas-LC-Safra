{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 3 - Regressão linear\n",
    "\n",
    "Na aula de hoje, vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) Introdução\n",
    "- 2) Regressão linear simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introdução\n",
    "\n",
    "Imagine que você quer vender sua casa.\n",
    "\n",
    "Você sabe os atributos da sua casa: quantos cômodos têm, quantos carros cabem na garagem, qual é a área construída, qual sua localidade, etc.\n",
    "\n",
    "Agora, a pergunta é: qual seria o melhor preço pra você colocá-la a venda, ou seja, quanto de fato ela vale?\n",
    "\n",
    "Você pode solicitar a avaliação de um corretor de imóveis (contando com a experiência dele), ou então...\n",
    "\n",
    "...fazer um modelo de **Machine Learning**, que, com base nos atributos e preços de diversas outras casas, pode fazer uma **predição** sobre o preço adequado da sua casa!\n",
    "\n",
    "Para resolver este problema, podemos utilizar um dos mais simples e importantes algoritmos de machine learning: a **Regressão Linear!**\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para introduzirmos as ideias, vamos usar um [dataset de preço de casas](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data).\n",
    "\n",
    "Esta base de dados contém **79 features** (+ 1 ID), que são as características de cada uma das casas listadas; e **1 target** (`SalePrice`), que é o preço pelo qual aquela casa foi vendida.\n",
    "\n",
    "Por termos o target disponível, estamos trabalhando com um problema de **aprendizagem supervisionada**.\n",
    "\n",
    "Para o significado de cada uma das features, e os valores que elas podem assumir, veja a página acima.\n",
    "\n",
    "**Vamos ler a base e começar a explorá-la!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:31:50.841829Z",
     "start_time": "2022-04-29T16:31:48.025595Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por enquanto, não vamos nos preocupar com os dados missing, pois vamos usar apenas uma feature no nosso modelo inicial.\n",
    "\n",
    "Aproveite para depois explorar os dados da forma que quiser!\n",
    "\n",
    "Por enquanto, vamos dar uma olhada na coluna target!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas antes, vamos identificar e diferenciar as features (X) do target (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Obs.: a coluna \"Id\" traz apenas um número de identificação arbitrário que não deve ser correlacionado com o target. Portanto, vamos desconsiderar esta coluna como feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:31:52.231954Z",
     "start_time": "2022-04-29T16:31:52.078637Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora sim, vamos olhar com carinho pro target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:31:54.308049Z",
     "start_time": "2022-04-29T16:31:54.198109Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomar o log de distribuições enviesadas tende a diminuir o desvio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:31:54.388001Z",
     "start_time": "2022-04-29T16:31:54.315050Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:31:55.038300Z",
     "start_time": "2022-04-29T16:31:55.024286Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fica evidente que a distribuição é desviada para a direita.\n",
    "\n",
    "Vamos tentar alterar isso na próximas versões do modelo para ver se teremos ganhos de performance!\n",
    "\n",
    "Por enquanto, seguimos assim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora dar uma olhada na correlação das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:31:55.676236Z",
     "start_time": "2022-04-29T16:31:55.040277Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em particular, podemos olhar a correlação entre as features e o target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:31:55.707950Z",
     "start_time": "2022-04-29T16:31:55.676236Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que a variável de área construída (\"GrLivArea\") é uma forte candidata a **explicar** o preço das casas, pois vemos calaramente uma correlação entre as variáveis!\n",
    "\n",
    "Mas note que há claramente dois outliers... \n",
    "\n",
    "Vamos retirá-los (por propositos pedagogicos - lembre-se de tentar entender o pq dos outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:31:57.258875Z",
     "start_time": "2022-04-29T16:31:57.229888Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora iniciar a construção de um modelo bem simples, que utilize a variável GrLivArea para predizer o preço!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:31:57.960072Z",
     "start_time": "2022-04-29T16:31:57.944361Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Regressão linear simples\n",
    "\n",
    "Apesar de alguns outliers, parece bem adequado que os pontos plotados acima sejam descritos por uma reta, não é mesmo?\n",
    "\n",
    "Ou, melhor dizendo: **a variável GrLivArea parece estar relacionada ao target SalePrice linearmente!**\n",
    "\n",
    "Para modelarmos esta relação, vamos conhecer o modelo de **Regressão Linear Simples**.\n",
    "\n",
    "Como o próprio nome diz, o modelo de Regressão Linear será **uma reta (polinômio linear)**, que melhor se ajusta aos seus dados!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo de **Regressão Linear Simples** será uma linha reta que relaciona Y (o preço da casa) e X (os atributos da casa). \n",
    "\n",
    "Se utilizarmos **apenas um atributo** (como, por exemplo, a área construída), temos uma **Regressão Linear Simples**, e nosso modelo é:\n",
    "\n",
    "$$ \\hat{y} = b_0 + b_1 X $$\n",
    "\n",
    "Neste caso, o modelo tem dois coeficientes (ou **parâmetros**) a serem determinados: $b_0$ (intercepto ou coeficiente linear) e $b_1$ (coeficiente angular). \n",
    "\n",
    "A equação acima exprime a **forma funcional** do conjunto de hipóteses com o qual trabalharemos: funções lineares, de uma úniva variável. Isto é,\n",
    "\n",
    "$$ f_{H, \\vec{b}} = b_0 + b_1 X $$\n",
    "\n",
    "Ou seja,\n",
    "\n",
    "$$ \\mathcal{H} = \\{ f_{H, \\vec{b}}\\} = \\{ b_0 + b_1 X \\} $$ \n",
    "\n",
    "é o conjunto de hipóteses que está sendo considerado, e o vetor de parâmetros é:\n",
    "\n",
    "$$\\vec{b} = \\begin{bmatrix}\n",
    "b_0\\\\ \n",
    "b_1\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "O **algoritmo de aprendizagem** do estimador é utilizado justamente para encontrarmos os coeficientes $b_0$ e $b_1$ (isto é, o vetor de parâmetros) **que melhor se ajustam aos dados!**\n",
    "\n",
    "Para fazer isso, pode-se utilizar o método dos **mínimos quadrados** (OLS  - ordinary least squares) ou então o [gradiente descendente](https://towardsdatascience.com/linear-regression-using-gradient-descent-97a6c8700931).\n",
    "\n",
    "Vamos conhecer o OLS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O algoritmo de aprendizagem da regressão linear\n",
    "\n",
    "De maneira esquemática, um algoritmo de aprendizagem recebe:\n",
    "\n",
    "- Um conjunto de hipóteses $\\mathcal{H}$;\n",
    "- Um conjunto de dados de treino $\\left(X_i, y_i \\right)$\n",
    "\n",
    "A partir destes inputs, o algoritmo constrói uma **função de perda**, que nada mais é que uma função que contabiliza **os erros cometidos pelo modelo**.\n",
    "\n",
    "E para sabermos o quanto um modelo está errando é muito simples: basta **compararmos o target predito $\\hat{y}$ com o target real $y$**!\n",
    "\n",
    "Isso pode ser feito de muitas maneiras. A \"maneira\" específica é o que determina a relação funcional da função de custo de interesse. Para regressão linear, a função de perda mais comum é o **erro quadrático (squared error)**:\n",
    "\n",
    "$$\\text{SE}= (y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "Onde $i = 1, 2, \\cdots, n$ é um índice que identifica cada uma das $n$ observações de treino.\n",
    "\n",
    "Obs.: se tomarmos a média do SE em toda a base de treino, temos o **Mean Squared Error** (MSE):\n",
    "\n",
    "$$\\text{MSE} = \\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "> Quando tomamos a função de erro para uma única observação, a chamamos de **função de perda**. Quando tomamos sua média sobre todo o dataset, a chamamos de **função de custo**. Na prática, os termos são usados como sinônimos (e, pro problema matemático a ser resolvido, tanto faz também)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://images.squarespace-cdn.com/content/v1/5acbdd3a25bf024c12f4c8b4/1600368657769-5BJU5FK86VZ6UXZGRC1M/Mean+Squared+Error.png width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, note uma coisa muito importante: **a função de custo é inteiramente dependente da função de hipótese (e, portanto, dos parâmetros!) e dos dados de treino!**\n",
    "\n",
    "De fato, para a i-ésima observação, $\\hat{y}_i = b_0 + b_1 X_i$ (note aqui a dependência da hipótese e dos dados!). Assim,\n",
    "\n",
    "$$(y_i-\\hat{y}_i)^2 = (y_i - (b_0 + b_1 X_i))^2 $$\n",
    "\n",
    "Por isso, escrevemos a função de custo como $\\mathcal{L}_{H, \\vec{b}}(X_i, y_i)$, para deixar claro que ela depende tanto dos dados $\\left(X_i, y_i \\right)$ quando da hipótese parametrizada:\n",
    "\n",
    "$$\\mathcal{L}_{H, \\vec{b}}(X_i, y_i) = \\sum_{i=1}^n(y_i - (b_0 + b_1 X_i))^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que temos uma função de custo, nosso objetivo passa a ser **minimizá-la**. E isso faz total sentido: queremos que nosso modelo, após ter \"aprendido\", erre o mínimo possível!\n",
    "\n",
    "Por isso, naturalmente caímos em um **problema de otimização**. Mas, a pergunta que surge é: queremos minimizar o erro **com relação a que?**\n",
    "\n",
    "Agora, é importante lembrarmos que a **função hipótese é parametrizada**. E é justamente o vetor de parâmetros que determina **a reta que melhor se ajusta aos dados**. \n",
    "\n",
    "Assim, podemos resumir o objetivo do algoritmo de aprendizagem como:\n",
    "\n",
    "> Determinar o vetor de parâmetros que minimiza a função de custo nos dados de treino\n",
    "\n",
    "E isso faz total sentido, não é mesmo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E, operacionalmente, isso é justamente o que queremos fazer:\n",
    "\n",
    "$$\\hat{b} = \\operatorname*{argmin}_b \\left( \\mathcal{L}_{H, \\vec{b}}(X_i, y_i) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe uma forma muito conhecida e natural para resolvermos problemas de otimização como este: o famoso \"deriva e iguala a 0\".\n",
    "\n",
    "E é exatamente o que o método OLS nos dá: através da otimização explícita da função de custo quadrática, temos uma expressão analítica para os parâmetros:\n",
    "\n",
    "$$ \\left\\{\\begin{matrix}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial b_0} = 0\\\\ \n",
    "\\frac{\\partial \\mathcal{L}}{\\partial b_1} = 0\n",
    "\\end{matrix}\\right. \n",
    "\\Rightarrow\n",
    "\\left\\{\\begin{matrix}\n",
    "\\hat{b}_1 = \\frac{\\sum_i (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_i (x_i - \\bar{x})^2}\\\\ \n",
    "\\hat{b}_0 = \\bar{y} - \\hat{b}_1 \\bar{x}\n",
    "\\end{matrix}\\right. \\ ,\n",
    "$$\n",
    "\n",
    "onde: $\\bar{x} = \\frac{1}{n} \\sum_i x_i$ e $\\bar{y} = \\frac{1}{n} \\sum_i y_i$, são os valores médios da feature e target, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para quem quiser saber detalhes sobre o procedimento acima, sugiro as referências citadas, ou então [este artigo super simples](https://are.berkeley.edu/courses/EEP118/current/derive_ols.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E esse é o algoritmo de aprendizagem da regressão linear!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 1 - construção do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos os dados, escolhemos o conjunto de hipóteses, e conhecemos também o algoritmo de treinamento da regressão linear!\n",
    "\n",
    "Felizmente, não precisamos implementar este algoritmo na mão (embora, caso queira, fique à vontade! É um ótimo exercício!)\n",
    "\n",
    "Aqui na aula, usaremos o sklearn para isso!\n",
    "\n",
    "Vamos começar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:31:58.147632Z",
     "start_time": "2022-04-29T16:31:58.071972Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que o modelo está treinado, podemos dar uma olhada nos coeficientes que foram encontrados!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:31:58.366412Z",
     "start_time": "2022-04-29T16:31:58.336429Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\vec{\\hat{b}} = \\begin{bmatrix}\n",
    "\\hat{b}_0\\\\ \n",
    "\\hat{b}_1\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "10895.38\\\\ \n",
    "112.12\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como interpretamos este resultado?\n",
    "\n",
    "O nosso modelo final é dado por:\n",
    "\n",
    "$$ \\hat{y} = \\mathcal{M} = f_{H, \\hat{\\vec{b}}}(X = \\text{GrLiveArea}) =  10895.38 + 112.12 \\text{GrLiveArea}$$\n",
    "\n",
    "Isto quer dizer que:\n",
    "\n",
    "> Aumentando a variável \"GrLiveArea\" em uma unidade faz com que o preço seja aumentado em USD 112.12!\n",
    "\n",
    "> O preço mínimo a ser pago, independente da área construída, é de 10895.38!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar o modelo treinado, neste caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:31:58.934948Z",
     "start_time": "2022-04-29T16:31:58.607218Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É raro que consigamos visualizar nosso modelo final como fizemos acima, mas no caso da regressão linear simples, temos essa sorte! :)\n",
    "\n",
    "Vamos agora fazer algumas previsões!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:32:00.377028Z",
     "start_time": "2022-04-29T16:32:00.344998Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou ainda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:32:00.456982Z",
     "start_time": "2022-04-29T16:32:00.381027Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pedizendo vários valores de uma vez (muito mais comum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:32:00.553944Z",
     "start_time": "2022-04-29T16:32:00.460983Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 2 - avaliação do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos o modelo treinado e algumas previsões, como avaliamos a performance do modelo?\n",
    "\n",
    "É nesse momento que entra em jogo a **base de teste**!\n",
    "\n",
    "Conheceremos agora algumas **métricas de avaliação**, que são medidas quantitativas para, de uma forma ou de outra, **comparar os targets reais com os targets preditos**.\n",
    "\n",
    "> Existem várias métricas de avaliação diferentes, e cada uma avalia **um aspecto particular** da performance do modelo.\n",
    "\n",
    "> Problemas de regressão e classificação admitem métricas de avaliação diferentes, dada a diferença entre os targets (contínuo vs discreto).\n",
    "\n",
    "Ao analisarmos estas métricas **calculadas na base de teste**, podemos ter uma ideia boa sobre o **poder de generalização** de nosso modelo, pois estaremos efetivamente testando o modelo com **observações que não foram utilizadas em sua construção!**\n",
    "\n",
    "Obs.: até podemos calcular as métricas de avaliação na base de treino, mas o propósito desse cálculo **não é a avaliação da generalização**. Veremos mais a frente em que contextos vale a pena calcularmos as métricas na base de treino. Mas, antes, vamos conhecer quais são as principais métricas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:32:00.925855Z",
     "start_time": "2022-04-29T16:32:00.849697Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observação: a coluna \"Id\" traz apenas um número de identificação arbitrário que não deve ser correlacionado com o target. Portanto, vamos desconsiderar esta coluna de nosso modelo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos conhecer algumas métricas para problemas de regressão!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em problemas de regressão, é uma boa ideia dar uma olhada nos **resíduos** das predições! Os resíduos nada mais são do que **os erros do modelo**, ou seja, **a diferença entre cada valor predito e o valor real**, para **os dados de teste!** Isto é,\n",
    "\n",
    "$$R(y_i) = y_i - \\hat{y}_i $$\n",
    "\n",
    "Rearranjando os termos, podemos escrever a equação acima como:\n",
    "\n",
    "$$ \\hat{y}_i= y_i - R(y_i)  $$\n",
    "\n",
    "Perceba, portanto, que um modelo perfeito (o que, lembre-se, é virtualmente impossível, e não o que queremos!), seria tal que $\\hat{y}_i= y_i$. Podemos visualizar este caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:32:01.179504Z",
     "start_time": "2022-04-29T16:32:00.927834Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O caso 100% perfeito (na prática, impossível) seria $y_i = \\hat{y}_i$, o que produziria uma reta exata!\n",
    "\n",
    "Quanto mais \"espalhados\" estiverem os pontos em torno da reta, em geral **pior é o modelo**, pois ele está errando mais!\n",
    "\n",
    "Uma forma de quantificar isso através de uma métrica conhecida como **$R^2$**, o **coeficiente de determinação**.\n",
    "\n",
    "Este coeficiente indica **o quão próximos os dados estão da reta ajustada**. Por outro lado, o $R^2$ representa a porcentagem de variação na resposta que é explicada pelo modelo.\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}{\\sum_{i=1}^n(y_i-\\bar{y})^2}$$\n",
    "\n",
    "É possível utilizar o $R^2$ nos dados de treino, mas temos que tomar muito cuidado com a forma como interpretaremos esta métrica! Discutiremos mais a diante a importância de calcularmos as métricas de avaliação também na base de treino.\n",
    "\n",
    "Por enquanto, vamos calcular o $R^2$ nos dados de teste apenas, como faremos a seguir. Essa métrica equivale, portanto, **ao gráfico que fizemos acima!**\n",
    "\n",
    "Então, quanto mais próximo de 1, melhor o modelo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:32:01.195495Z",
     "start_time": "2022-04-29T16:32:01.182501Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra coisa importante é que os resíduos sejam normalmente distribuídos (isso faz parte das premissas da visão mais estatística da regressão linear). Se esse não for o caso, pode ser importante que você reveja se a regressão linear de fato é um modelo adequado ao seu problema.\n",
    "\n",
    "Mas, de maneira mais genérica, é interessante avaliarmos a **distribuição dos resíduos** para termos uma ideia da distribuição dos erros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:32:01.291573Z",
     "start_time": "2022-04-29T16:32:01.200495Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além dos resíduos, existem três principais **métricas de avaliação** do modelo de regressão linear:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Absolute Error** (MAE) é a média do valor absoluto de todos os resíduos (erros):\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
    "\n",
    "**Mean Squared Error** (MSE) é a média dos erros quadrados:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "**Root Mean Squared Error** (RMSE) é a raiz quadrada da média dos erros quadrados:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n",
    "\n",
    "**Mean absolute percentage error** (MAPE) é o erro absoluto médio relativo ao valor real dos targets:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n \\left | \\frac{y_i-\\hat{y}_i}{y_i} \\right| $$\n",
    "\n",
    "Comparando as métricas:\n",
    "\n",
    "- **MAE** é a mais simples de entender, mas ela penaliza mais erros menores;\n",
    "- **MSE** é a métrica mais popular, pois essa métrica penaliza mais erros maiores, o que faz mais sentido na maior parte das aplicações reais.\n",
    "- **RMSE** é ainda mais popular, pois esta métrica está nas mesmas unidades que o target.\n",
    "- **MAPE** penaliza mais resíduos negativos (isto é, erros pra cima) do que residuos positivos (erros pra baixo).\n",
    "    - $y_i = 100$ e $\\hat{y}_i = 150$ (erro pra cima). Temos: $\\text{MAPE} = \\left | \\frac{100 - 150}{100} \\right| = 50 \\%$\n",
    "    - $y_i = 200$ e $\\hat{y}_i = 150$ (erro pra baixo). Temos: $\\text{MAPE} = \\left | \\frac{200 - 150}{200} \\right| = 25 \\%$\n",
    "\n",
    "Estas métricas todas podem ser utilizadas como **funções de custo** a serem minimizadas pelo algoritmo do estimador.\n",
    "\n",
    "Inclusive, já conhecemos uma delas: O MSE, que é usado como função de custo para o OLS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:32:01.736101Z",
     "start_time": "2022-04-29T16:32:01.643150Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dar uma olhada em tudo junto:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T16:32:01.988953Z",
     "start_time": "2022-04-29T16:32:01.915000Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E é isso, passamos pela primeira vez pelo ciclo de modelagem! Muito legal, não é mesmo?\n",
    "\n",
    "Mas, claro, é difícil de acreditar que um modelo tão simples, com uma única feature, é o melhor que podemos fazer.\n",
    "\n",
    "Que tal fazermos algumas mudanças? Vamos entrar no ciclo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Como garantir que nosso modelo não está sofrendo de overfitting?__\n",
    "\n",
    "Naturalmente, essa é uma pergunta de extrema importância, especialmente no contexto de **redes neurais**. [Veja aqui](https://towardsdatascience.com/8-simple-techniques-to-prevent-overfitting-4d443da2ef7d) e [aqui](https://towardsdatascience.com/dont-overfit-how-to-prevent-overfitting-in-your-deep-learning-models-63274e552323) algumas discussões.\n",
    "\n",
    "Na prática: **jamais se apegue à peformance de treino como forma de avaliar o modelo!** \n",
    "\n",
    "O que queremos otimizar sempre será a performance **avaliada nos dados de teste**, isto é, a **performance de generalização** do modelo. \n",
    "\n",
    "Assim, é **avaliando o modelo nos dados de teste** que garantimos que uma boa performance não é produto do overfitting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
